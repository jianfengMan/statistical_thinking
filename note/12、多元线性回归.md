多元回归模型 multtiple regression model 

$y=\beta_{0}+\beta_{1} x_{1}+\beta_{2} x_{2}+\cdots+\beta_{k} x_{k}+\varepsilon$



### 线性关系检验

线性关系检验是检验因变量y与k个自变量之间的关系是否显著，也称为总体显著性检验。检验的具体步骤如下：

1、提出假设

$H_{0}: \beta_{1}=\beta_{2}=\dots=\beta_{k}=0$

$H_{1}: \beta_{1}=\beta_{2}=\dots=\beta_{k}=0$至少有一个不等于0

2、计算检验的统计量 F

$F=\frac{\mathrm{SSR} / k}{S S E /(n-k-1)} \sim F(k, n-k-1)$

3、做出统计决策



**多重共线性及其所产生的问题**

当回归模型中两个或两个以上的自变量彼此相关时，则称回归模型中存在多重共线性 multicollinearity，在实际问题中，所使用的的自变量之间存在相关是一件很平常的事，但是回归分析中存在多重共线性时将会产生问题



**变量选择与逐步回归**

**变量选择过程**：选择自变量的原则通常是对统计量进行显著性检验，检验的根据是：将一个或一个以上的自变量引入回归模型中时，是否使残差平方和SSE显著减少。如果增加一个自变量使残差平方和(SSE) 显著减少，则说明有必要将这个自变量引入回归模型

确定在模型中引入自变量$x_i$是否使残差平方和(SSE)显著减少的方法，就是使用F统计量的值作为一个标准，以此来确定是在模型中增加一个自变量，还是从模型中提出一个自变量



除了逐步回归外，岭回归(ridge regression) 是一种专门用于多重共线性数据分析的回归方法，它实际上是一种改良的最小二乘法，通过放弃最小二乘法的无偏性，以损失部分信息，降低精度为代价来寻找效果稍差但回归系数更符合实际的回归方程